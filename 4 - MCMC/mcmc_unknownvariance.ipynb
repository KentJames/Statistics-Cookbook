{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Monte Carlo\n",
    "## Unknown Variance\n",
    "\n",
    "This notebook walks through how to implement a simple markov chain monte carlo analysis using Metropolis hastings for a model where both mean and\n",
    "variance is unknown.\n",
    "\n",
    "MCMC analysis searches some N-Dimensional space for some mode of a distribution. The process is as follows:\n",
    "\n",
    "1) Choose Random Start mean and standard deviation, $\\theta_0$, $\\sigma_0$. \n",
    "\n",
    "2) At step i = 1,..,N, propose a new parameter $\\theta_i,\\sigma_i$ which is drawn from some distribution with a mean theta_i, and covariance matrix Sigma, where:\n",
    "\n",
    "$$\\Sigma = \\begin{bmatrix} \\tau_\\theta^2 & 0 \\\\ 0 & \\tau_\\sigma^2 \\end{bmatrix}$$\n",
    "\n",
    "$\\tau_\\theta^2$ and $\\tau_\\sigma^2$ are chosen to suit the model and space being fit to. (Trial and error)\n",
    "\n",
    "3) Evaluate the ratio:\n",
    "\n",
    "$$r = \\frac{P(\\theta_i, \\sigma_i | y)}{P(\\theta_{i-1},\\sigma_{i-1} | y)}$$\n",
    "\n",
    "4) Accept $\\theta_p$ with some probability.\n",
    "\n",
    "5) Repeat steps 2-4 until you converge.\n",
    "\n",
    "The posterior distribution being evaluated in this case is:\n",
    "\n",
    "$$P(\\mu,\\sigma^2 | y) \\propto (\\sigma^2)^{-(n+2)/2} \\exp{\\Bigg[\\frac{-1}{2\\sigma^2}\\Big[\\big(n-1\\big)s^2 + n\\big(\\bar{y}-u\\big)^2}\\Big] \\Bigg]$$\n",
    "\n",
    "It can be seen from the output that the mean follows a Students t-distribution, and the variance follows a $\\chi^2$ distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the probability space we are going to be searching. We are using a one dimensional gaussian with an undetermined mean and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Statistics of space we are searching\n",
    "meanx=5\n",
    "sigmax = 2\n",
    "Nx = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our joint probability distribution for both the mean and the variance. The first definition is the naive implementation, which turned out to have poor numerical stability.\n",
    "\n",
    "The second definition gives a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The raw posterior\n",
    "def posterior_space(mean,sigma,N,curr_param):\n",
    "    \n",
    "    cps = curr_param[1]\n",
    "\n",
    "    p1 = numpy.power(cps,-(float(N)+2)/2)\n",
    "    #print(p1)\n",
    "    p2 = (N-1) * numpy.square(sigma)\n",
    "    p3 = N*numpy.square(mean - curr_param[0])\n",
    "    p4 = -1/(2 * cps)\n",
    "    p5 = numpy.exp(p4*(p2+p3))\n",
    "    #print(p5)\n",
    "    return  (curr_param[1] > 0) * p1 * p5\n",
    "\n",
    "#More numerically stable\n",
    "def posterior_space_2(mean,sigma,N,curr_param):\n",
    "    \n",
    "    p1 = numpy.power(curr_param[1],-N+2)\n",
    "    p2 = (N-1)*numpy.square(sigma)\n",
    "    p3 = N * numpy.square((mean - curr_param[0]))\n",
    "    p4 = (2 * numpy.square(curr_param[1]))\n",
    "    \n",
    "    return (curr_param[1] > 0) * p1 * numpy.exp(-1*(p2+p3)/p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters for our markov chain and execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of markov chain steps\n",
    "n_mc = 1000\n",
    "\n",
    "#Proposal Scales\n",
    "tau_mu = 0.6\n",
    "tau_sigma = 0.1\n",
    "\n",
    "#For applying random noise\n",
    "proposal_covariance = numpy.asarray([[numpy.square(tau_mu),0],[0,numpy.square(tau_sigma)]])\n",
    "proposal_covariance = proposal_covariance/1\n",
    "cholesky = numpy.linalg.cholesky(proposal_covariance)\n",
    "\n",
    "markov_chain = numpy.zeros((n_mc,2))\n",
    "markov_chain[0] = [3.2,8.6]\n",
    " \n",
    "acceptances = 0\n",
    "\n",
    "\n",
    "for i in numpy.arange(n_mc-1):\n",
    "    #Find value from current point in markov chain.\n",
    "    current_val = markov_chain[i,:]\n",
    "    \n",
    "    #Propose a new value.\n",
    "    proposed = current_val + numpy.dot(cholesky,numpy.random.randn(2))\n",
    "    \n",
    "    #Probability Density Function\n",
    "    current_pdf = posterior_space_2(meanx,sigmax,Nx,current_val)\n",
    "    proposed_pdf = posterior_space_2(meanx,sigmax,Nx,proposed)\n",
    "    \n",
    "    #Find Ratio\n",
    "    r = proposed_pdf / current_pdf\n",
    "    \n",
    "    #If Ratio wins over random number, accept.\n",
    "    #Else keep current value, advance markov chain regardless.\n",
    "    rand = numpy.random.rand()\n",
    "    if r > rand:\n",
    "        markov_chain[i+1] = proposed\n",
    "        acceptances += 1\n",
    "    else:\n",
    "        markov_chain[i+1] = current_val\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is a bit messier than the markov chain for a bivariate gaussian with a known variance, due to the extremely small first differential of sigma with respect to the evaluated P.d.f value. Ultimately, running the chain for long enough causes it to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
